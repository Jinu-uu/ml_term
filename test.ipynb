{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남자1.wav [0.00024414 0.00024414 0.00024414 ... 0.03076172 0.04003906 0.04785156] 0\n",
      "남자2.wav [ 0.00024414  0.00024414  0.00024414 ... -0.04003906 -0.04199219\n",
      " -0.03808594] 1\n",
      "남자3.wav [0. 0. 0. ... 0. 0. 0.] 2\n",
      "남자4.wav [ 0.          0.          0.         ... -0.03655984 -0.03834914\n",
      " -0.03776056] 3\n",
      "남자5.wav [0.00024414 0.00024414 0.00024414 ... 0.00024414 0.00024414 0.00024414] 4\n",
      "석원.wav [ 0.03164673  0.03018188  0.0296936  ... -0.00244141 -0.00247192\n",
      " -0.00314331] 5\n",
      "여자1.wav [ 0.00024414  0.00024414  0.00024414 ... -0.03222656 -0.02685547\n",
      " -0.03222656] 6\n",
      "여자5.wav [ 0.00021362  0.00021362  0.00021362 ... -0.00024414  0.00045776\n",
      "  0.0007019 ] 7\n",
      "염.wav [-0.00115967 -0.00064087 -0.00024414 ...  0.00906372  0.0045166\n",
      " -0.00454712] 8\n",
      "팡민-_mp3cut.net_.wav [-0.02630615 -0.0244751  -0.01773071 ... -0.00183105  0.0045166\n",
      " -0.01629639] 9\n",
      "[[ 42.   9.   0.   0.   0.   1.   0.   0.   0.   0.]\n",
      " [ 96.  39.  46.  73.  58.  73. 132.   0.  40.  25.]\n",
      " [  0.   0.  53.   0.   0.   8.   0.   0.   1.   0.]\n",
      " [ 17.   6.   4.  85.   8.  18.   9.  29.  70.  29.]\n",
      " [  0.   0.   3.   0.  19.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  14.   7.   2.  60.   0.   0.  17.  13.]\n",
      " [ 14.   0.   0.   0.   0.   3.  32.  14.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   2.   0.   7.   1.   2.]\n",
      " [  0.   0.   0.   0.   1.   8.   0.   0.  54.   4.]\n",
      " [ 32. 147.  81.  36. 113.  28.  28. 151.  18. 128.]]\n",
      "0.2582089552238806\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 163\u001b[0m\n\u001b[0;32m    160\u001b[0m         print_score()\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 158\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    155\u001b[0m     try_svc()\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(train_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgmm\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 158\u001b[0m     \u001b[43mtry_gmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m print_score()\n",
      "Cell \u001b[1;32mIn[3], line 117\u001b[0m, in \u001b[0;36mtry_gmm\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m estimator \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39mn_classes,\n\u001b[0;32m    112\u001b[0m           covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    114\u001b[0m estimator\u001b[38;5;241m.\u001b[39mmeans_init \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([train_data[train_label \u001b[38;5;241m==\u001b[39m i]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    115\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_classes)])\n\u001b[1;32m--> 117\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m result \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(test_data)\n",
      "File \u001b[1;32mc:\\Users\\kland\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\mixture\\_base.py:200\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    The method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m        The fitted mixture.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kland\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\mixture\\_base.py:265\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    262\u001b[0m prev_lower_bound \u001b[38;5;241m=\u001b[39m lower_bound\n\u001b[0;32m    264\u001b[0m log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_step(X)\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_resp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(log_resp, log_prob_norm)\n\u001b[0;32m    268\u001b[0m change \u001b[38;5;241m=\u001b[39m lower_bound \u001b[38;5;241m-\u001b[39m prev_lower_bound\n",
      "File \u001b[1;32mc:\\Users\\kland\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:755\u001b[0m, in \u001b[0;36mGaussianMixture._m_step\u001b[1;34m(self, X, log_resp)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariances_ \u001b[38;5;241m=\u001b[39m _estimate_gaussian_parameters(\n\u001b[0;32m    752\u001b[0m     X, np\u001b[38;5;241m.\u001b[39mexp(log_resp), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_covar, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_type\n\u001b[0;32m    753\u001b[0m )\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_ \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m--> 755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecisions_cholesky_ \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_precision_cholesky\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariances_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_type\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kland\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:347\u001b[0m, in \u001b[0;36m_compute_precision_cholesky\u001b[1;34m(covariances, covariance_type)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39mless_equal(covariances, \u001b[38;5;241m0.0\u001b[39m)):\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(estimate_precision_error_message)\n\u001b[0;32m    348\u001b[0m     precisions_chol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(covariances)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m precisions_chol\n",
      "\u001b[1;31mValueError\u001b[0m: Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC \n",
    "import random\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import os\n",
    "\n",
    "sampling_rate = 0\n",
    "path = './test_data2'\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "result = []\n",
    "\n",
    "def getpath(file):\n",
    "    return os.path.join(path, file)\n",
    "\n",
    "def cut_file(data, index):\n",
    "    global sampling_rate\n",
    "    \n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    index = index % 4\n",
    "    \n",
    "    for i in range(0, sampling_rate * 10):\n",
    "        if int(sampling_rate * 2 * index) <= i and i < int(sampling_rate * 2 * (index + 1)):\n",
    "            test.append(data[i])\n",
    "        else:\n",
    "            train.append(data[i])\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "def load_wav_files_from_path():\n",
    "    global mfcc_data, train_data, test_data, train_label, test_label\n",
    "    \n",
    "    files = os.listdir('./test_data2')\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        file_data, sr = librosa.load(getpath(file), sr=sampling_rate)\n",
    "        file_data = file_data[:sampling_rate * 10]\n",
    "        \n",
    "        print(file, file_data, i)\n",
    "\n",
    "        train, test = cut_file(file_data, i)\n",
    "        \n",
    "        train = np.array(train)\n",
    "        test = np.array(test)\n",
    "        \n",
    "        mfcc_train = librosa.feature.mfcc(y=train, sr=sampling_rate, n_mfcc=40, hop_length = int(sampling_rate / 100))\n",
    "        mfcc_test = librosa.feature.mfcc(y=test, sr=sampling_rate, n_mfcc=40, hop_length = int(sampling_rate / 100))\n",
    "        \n",
    "        mfcc_train = mfcc_train.T\n",
    "        mfcc_test = mfcc_test.T\n",
    "        \n",
    "        for mfcc_train_datum in mfcc_train:\n",
    "            train_data.append(mfcc_train_datum)\n",
    "            train_label.append(i)\n",
    "            \n",
    "        for mfcc_test_datum in mfcc_test:\n",
    "            test_data.append(mfcc_test_datum)\n",
    "            test_label.append(i)\n",
    "            \n",
    "def shuffle_data():\n",
    "    global train_data, train_label, test_data, test_label\n",
    "    \n",
    "    train_comp = list(zip(train_data, train_label))\n",
    "    test_comp = list(zip(test_data, test_label))\n",
    "        \n",
    "    random.shuffle(train_comp)\n",
    "    random.shuffle(test_comp)\n",
    "        \n",
    "    train_data, train_label = zip(*train_comp)\n",
    "    test_data, test_label = zip(*test_comp)\n",
    "        \n",
    "    train_data = list(train_data)\n",
    "    train_label = list(train_label)\n",
    "    \n",
    "    test_data = list(test_data)\n",
    "    test_label = list(test_label)\n",
    "    \n",
    "    train_data = np.array(train_data)\n",
    "    train_label = np.array(train_label)\n",
    "    \n",
    "    test_data = np.array(test_data)\n",
    "    test_label = np.array(test_label)\n",
    "    \n",
    "def try_svc():\n",
    "    global train_data, train_label, test_data, result\n",
    "    \n",
    "    svc = SVC(C=1.0, kernel='sigmoid', random_state=0)\n",
    "    svc.fit(train_data, train_label)\n",
    "    \n",
    "    result = list(svc.predict(test_data))\n",
    "    \n",
    "def try_gmm():\n",
    "    global train_data, train_label, test_data, test_label, result\n",
    "    n_classes = 10\n",
    "    \n",
    "    estimator = GaussianMixture(n_components=n_classes,\n",
    "              covariance_type='diag', max_iter=10)\n",
    "    \n",
    "    estimator.means_init = np.array([train_data[train_label == i].mean(axis=0)\n",
    "                                    for i in range(n_classes)])\n",
    "        \n",
    "    estimator.fit(train_data)\n",
    "    result = estimator.predict(test_data)\n",
    "    \n",
    "def print_score():\n",
    "    global result, test_label\n",
    "    \n",
    "    conf = np.zeros((10, 10))\n",
    "    \n",
    "    for i in range(len(result)):\n",
    "        conf[result[i]][test_label[i]] += 1\n",
    "    print(conf)\n",
    "    \n",
    "    no_correct = 0\n",
    "    \n",
    "    for i in range(10):\n",
    "        no_correct += conf[i][i]\n",
    "        \n",
    "    accuracy = no_correct / len(result)\n",
    "    \n",
    "    print(accuracy)\n",
    "    \n",
    "def main():\n",
    "    global sampling_rate, path, train_data, test_data, train_label, test_label\n",
    "    train_type = ''\n",
    "    \n",
    "    sampling_rate = 16000\n",
    "    path = './test_data2'\n",
    "    \n",
    "    load_wav_files_from_path()\n",
    "    shuffle_data()\n",
    "    \n",
    "    while(train_type != 'exit'):\n",
    "        train_type = input('(svc | gmm): ')\n",
    "        \n",
    "        if(train_type.lower() != 'svc' and train_type.lower() != 'gmm'):\n",
    "            continue\n",
    "        \n",
    "        if(train_type == 'svc'):\n",
    "            try_svc()\n",
    "            \n",
    "        elif(train_type == 'gmm'):\n",
    "            try_gmm()\n",
    "            \n",
    "        print_score()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
